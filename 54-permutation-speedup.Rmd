---
title: "54-permutation-speedup"
output: html_notebook
---

# 54-permutation-speedup

# Speedup Investigation

The purpose of this notebook is to explore ways to speed up the calculation of the permutation importance.  Here, we just generate the dataset and some models, as we would do similarly in the 70 series.

**Run 10, 30, 40, and 50 prior to running this notebook.**

```{r library imports}
pacman::p_load(tidyverse, furrr, h2o, tictoc)
```

Load up the data using abridged feature set and simple datatype settings:
```{r generate data}
filebase = '/scratch/p_gaydosh_lab'

## load waves and join them
wave_data <- load_waves(1:5, filebase=filebase)
full_dataset <- get_working_dataset_full(wave_data, join_type = 'full')

## set outcome variable of interest
outcome = 'h5mn8'

## get the aids that you want
inner_aids <- get_inner(list(wave_data[[1]], wave_data[[3]], wave_data[[4]], wave_data[[5]]))

## use the features and ids that you want to select out what you want
working_ds <- full_dataset %>%
  remove_subjects_not_in_wave1(filebase=filebase) %>%
  filter(aid %in% inner_aids) %>%
  dplyr::select(all_of(c('aid', emotional_despair_predictors, cognitive_despair_predictors, outcome))) %>%
  mutate_all(as.factor) %>%
  drop_na(outcome)

#working_ds %>% glimpse()
```
Split the data:
```{r, message=FALSE, warning=FALSE}
## split the data into relevant proportions desired
data_splits <- working_ds %>%
  split_data(strat_var = outcome, ratios=c(0.7, 0.2, 0.1))

# assemble list
training_df <- data_splits$train
validation_df <- data_splits$valid
testing_df <- data_splits$test
```

Initializations for h2o and set furrr to be multiprocess:
```{r}
h2o.init()
future::plan(multiprocess)
```

Here, we'll generate some LASSO models because they train leaps and bounds faster.

```{r generate lasso models}
lasso_params <- list(alpha = c(1))
# Call modeling function using function parameters and show visualization of results.  Recommend the number of features that should be used.  Report performance metric stats.

n_boot = 50

lasso_mdls <- model_feature_selection( "Lasso",
                                          training_frame = training_df,
                                          validation_frame = validation_df,
                                          hyper_params = lasso_params,
                                          outcome = outcome, 
                                          n = n_boot)
```

Now, let's investigate if there is any speedup to using `future_map_dfr` vs `map_df`.  I'll basically run this cell twice, changing the function under the covers, and report the results.

```{r}
future::plan(multiprocess)
```


```{r}
tic()
boot_lasso_perm_plt <- lasso_mdls$models %>%
  get_aggregated_permute_imp(training_df, outcome=outcome)
toc()
```
To implement this, I put `future_map_dfr` inside the `get_aggregated_permute_imp` function so that the `future_map` separates the model list into individual models.

- *Without* `future_map`, this takes 1054.431 seconds = 17.6 minutes.
- *With* `future_map`, this takes 101.993 = 1.7 minutes. 

This is a fantastic speedup; 10x.
It is worth knowing how this will work with memory constraints.  What if I do 50 bootstraps?  Worked.  310.098 seconds = 5.17 minutes.

I also tried adding another `future_map` in where we permute all 50 variables.  This was ineffective, and it still took the same 5.17 minutes.

Lastly, I tried removing the `future_map_dfr` from `get_aggregated_permute_imp` and instead put it in the `permute_var_imp` function so that the 50 variable permutation would run faster.  This had even worse performance, and took 1701.444 seconds = 28.4 minutes.

All implementations appeared to return the correct size dataframe, correctly populated with differences.
```{r}
met <- 'pr_auc'
boot_lasso_perm <- boot_lasso_perm_plt %>%
  get_permute_placement(metric_oi=met) %>%
  add_attribute_names('predictor', full_dataset) %>%
  dplyr::select(predictor, everything())

head(boot_lasso_perm, 20)
```
Amazing.

# Verification of string use
As of commit e9021ab, `plot_permute_var_imp` doesn't receive a string and uses tidy evaluation to find the parameter in the associated dataframe.  However, this means that we need to set it manually since the others receive a string.  I'll convert that functionality and verify its behavior here.

```{r plot lasso permutation, fig.width = 10, fig.height = 12}
plot_permute_var_imp(boot_lasso_perm, metric = met)
```
This function has been verified to work correctly using the code above, as we would expect to use it in the 70 series.