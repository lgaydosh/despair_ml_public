---
title: "41-modeling-rf"
output: html_notebook
---

The purpose of this document is to build bootstrap training data n number of times and train n different random forest models and extract 
#Steps Taken

1. Splitting the data. [x]
2. Bootstrapping the training set n times (n = 1000). [x]
3. Splitting the bootstrap set into a training a validation set. [x]
4. Creating n different models. [x]
- finding the best tuning parameters for each model using grid search (Tuning parameters: ntrees and max_depth).[x]
- creating a final model (using k-fold cross validation) that uses the best tuning parameters from the previously conducted grid search.[x]
- fitting the model onto the validation set created earlier.[x]
5. Saving all models and the performance metrics into a list. [x]
6. Evaluation of all model parameters and the stability of those parameters.  


```{r random forest model function}
# This function gets the best features for the random forest by bootstrapping it n number of times
# Each bootstrapped model is then used to create 
rf_feature_selection <- function(training_df, 
                                 n = 2, 
                                 k = 5, 
                                 max_depths_tune = c(100,150,200), 
                                 ntree_tune = c(5,10,25), 
                                 outcome, 
                                 top_n = 20){
  # training_df : training data frame sent in after initial 70-30 split
  # n : n number of bootstrapped
  # k : k folds in cross-validation
  # max_depths_tune : tuning parameters to test for the max depth
  # ntree_tune : tuning parameters to test for number of trees in the random forest
  # outcome : name of the outcome variable
  # top_n : top n important variables to be extracted from the models generated
  # return : a list of three lists: 
  #          list 1 - all models created
  #          list 2 - all model performances
  #          list 3 - all dataframes of variable importances with the top_n variables in it
  
  

  
  #create bootstraps list
  straps <- training_df %>%bootstraps(times = n, strata = outcome)
  
  #lists to store results and models that are created on each bootstrap
  combined_models <- list()
  combined_performances <- list()
  variable_imps <- list()
  
  
  # Train the model on each of the bootstraps and get the performance 
  for(i in 1:length(straps$splits)){
    results <- as.data.frame(straps$splits[[i]])%>%
      boot_model_rf(outcome = outcome, max_depths_tune = max_depths_tune, ntrees_tune = ntree_tune, nfolds = k)
    combined_models[[i]] <- results[[1]]
    combined_performances[[i]] <- results[[2]]
    variable_imps[[i]] <- get_top_n_names(results[[1]], 20)
    
  }
  
  
  return(list(combined_models, combined_performances, variable_imps)) 
  
}

```



```{r}
rf_feature_selection(training_df,outcome = "h5mn8")
```

