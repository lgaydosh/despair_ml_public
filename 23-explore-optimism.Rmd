---
title: "23-explore-optimism"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: lumen
    code_folding: hide
editor_options: 
  chunk_output_type: inline
---

# Purpose

The purpose of this document is to perform EDA on the optimism outcome variables. Additionally, this is meant to serve primarily as a teaching example for the master's students and help to focus and guide their EDA for refactoring their own code. For the sake of this exploration, we'll focus in on `h4pe7` ("I am always optimistic about my future") after looking generally at missingness in the data. 

The optimism variables are: \ 
   
  **Wave 4**:\
    1. `hpe7` : I'm always optimistic about my future \
    2. `h4pe15`: I hardly ever expect things to go my way \
    3. `h4pe23`: I expect more good things to happen to me than bad \
    4. `h4pe31`: I rarely count on good things happening to me \
    \
  **Wave 5**:\
    1. `h5pe1`: I'm always optimistic about my future \
    2. `h5pe2`: I hardly ever expect things to go my way \
    3. `h5pe3`: I expect more good things to happen to me than bad \


# Libraries and data import

```{r load libraries}
# Load required libraries
librarian::shelf(tidyverse, haven, DataExplorer, tictoc, janitor, quiet = TRUE)
```

```{r read in data, cache=TRUE}

# Create path names - note that we only need waves 4 and 5 for exploring optimism
wave_files <- str_c("Z:/Gaydosh/Core Files/In Home Interview Files/wave"
               ,4:5,
               ".xpt")

# read in files with map and time it
# 122.55 seconds to read in data
tic()
wave_data <- wave_files %>%
  map(read_xpt)
toc()
```

Reading in the data takes approximately 2 minutes.

```{r join data, cache=TRUE}
# Join data into a single data frame - return all rows from wave 4 and all columns from both
data_combined <- left_join(wave_data[[1]], 
                           wave_data[[2]], 
                           by = "AID") %>% 
  clean_names(case = "snake")

# Determine if anything was not joined in
not_joined <- anti_join(wave_data[[1]], wave_data[[2]], by = "AID")
```

Note, there are 4787 unique AID values from wave 4 that are not present in wave 5. For the sake of this exploration the dropped values will be ignored. 

# Selecting Variables

```{r vectors of vars to select, echo=FALSE}

# From file 10

# vector of optimism variables
optimism_list <- c("h4pe7","h5pe1","h4pe15","h5pe2","h4pe23","h4pe31","h5pe3")

# Predictors of interest
predictor_list <- c("h4id5j",
         "h4pe6",
         "h4pe14",
         "h4pe22",
         "h4pe30",
         "h4pe7",
         "h4pe15",
         "h4pe23",
         "h4pe31",
         "h5id6i",
         "h5pe1",
         "h5pe2",
         "h5pe3",
         "h1fs1",
         "h3sp5",
         "h4mh18",
         "h1fs3",
         "h3sp6",
         "h4mh19",
         "h5ss0a",
         "h1fs4",
         "h3sp7",
         "h4mh20",
         "h1fs5",
         "h3sp8",
         "h4mh21",
         "h1fs6",
         "h3sp9",
         "h4mh22",
         "h5ss0b",
         "h1fs7",	
         "h3sp10",
         "h4mh23",
         "h1fs11",
         "h4mh24",
         "h5ss0c",
         "h1fs15",
         "h3sp11",
         "h4mh25",
         "h1fs16",
         "h3sp12",
         "h4mh26",
         "h5ss0d",
         "h1fs17",
         "h3sp13",
         "h4mh27",
         "h4id5h",
         "h5id6g")
```

```{r brief exploration of variable sets, eval=TRUE, include=FALSE, echo=FALSE}

# all optimism variables in predictor list
optimism_list %in% predictor_list

# Variables not in waves 4 or 5 (not files read in, at least)
missing_preds <- setdiff(predictor_list, names(data_combined))

# Variables to select: dropped variables that are not in wave 4 or 5
preds_select <- setdiff(predictor_list, missing_preds)
```

Note, all optimism variables are already included in the `predictor_list` from file 10, so the optimism variables vector is superfluous.

Additionally, 19 variables are not in wave 4 or 5 (see `missing_preds`).

```{r select variables of interest, warning=FALSE, include=FALSE}
# Note: preds_select is external vector from above code chunk
final_data <- data_combined %>%
  dplyr::select(aid, tidyselect::all_of(preds_select))
```

# Begin to understand the dataset with introductory plot

```{r}
final_data %>% 
  plot_intro()
```

The introductory plot shows us that that we need to be careful about using `drop_na()` because that will be dropping approximately 1/3 of all observations. Further, the introductory plot shows that it all outcomes are coded as continuous variables, which will be fine for this exploratory analysis, but because all data is discrete, all outcomes should probably be converted to factors.

# Missing value exploration

```{r Explore missing data}

# Overview of missing data
final_data %>% 
  plot_missing()
```

From `plot_missing()` we see that there are 9 variables with approximately 30% missingness. How many people have missing values across multiple variables?

```{r how many people have missing values across multiple variables}
# Gain insight into who has these missing values. 
# Are these missing values the same people?

# Get the actual values of missingness we care about
missing_counts <- final_data %>%
  map_df(~sum(is.na(.))) %>% 
  pivot_longer(cols = everything(),
               names_to = "var") %>%
  filter(value > 1)

# Names of variables with missingness we care about
missing_vars <- missing_counts %>% pull(var)

# Get total missingness by each individual across all variables
total_missing <- final_data %>% 
  dplyr::select(all_of(missing_vars)) %>% 
  rowwise() %>% 
  is.na() %>%
  rowSums()

# Bar plot of missingness for variables with more than 1 person missing
final_data %>% 
  mutate(tot_miss = total_missing) %>% 
  dplyr::select(aid, tot_miss) %>% 
  group_by(tot_miss) %>% 
  summarise(counts = n()) %>% 
  ggplot() +
  geom_bar(aes(x = tot_miss, y = counts), stat = "identity", fill = "light blue") +
  scale_x_continuous(breaks = seq(0,9,1)) +
  scale_y_continuous(breaks = seq(0,11e3, 1e3)) +
  ggtitle("Count of individuals with different numbers of missing variables") +
  xlab("Number of variables with missing value") +
  theme_dark()
```

From the barplot we see that just under 5000 people have 9 variables missing, just over 10,000 have no missing values, and fewer than 250 people are missing 1, 2, 3, 4, 5, or 6. Using `drop_na()` will result in too much missing information without explanation for why approximately 5000 people are missing those variables.

Additional questions possible to answer in iteration: \

  1. Are these variables redundant to each other? \
  2. Do they cluster together? If so, how? \
  3. Are they predictive of each other? \
  4. Are they correlated?
  
```{r correlation plot among variables with high missingness, cache=TRUE}

# replace all missing values with 99 for the sake of exploring correlation
cor_dat <- final_data %>% 
  select(all_of(missing_vars)) %>% 
  mutate_all(~replace_na(., 99)) %>% 
  cor(method = "kendall")

# Correlation plot of missing variables
cor_dat %>% 
  corrplot::corrplot(method = "color", 
                     type = "upper", 
                     order = "hclust", 
                     diag = FALSE, 
                     addCoef.col = "black")

```

The correlation plot shows that the 9 variables with high missingness are all positively correlated, some are especially highly correlated (`h5ss0a` and `h5ss0b` have 0.89 correlation, for instance). The way the correlations look seems to imply that sets of questions didn't apply or were overlooked. Further, the `order = "hclust"` option automatically clusters the variables together using heirarchical clustering. This ostensibly reveals two clusters, vertically split at the variable `h5ss0b`. To the right are the variables `h5pe2` and `h5ss0c`, to the left is everything else.

# Explore outcome variables

```{r assess change over time of primary outcome}

# h5pe1 and h4pe7
h5pe1_change_plot <- final_data %>% 
  select(aid, h4pe7, h4pe15, h4pe23, h5pe1, h5pe2, h5pe3) %>% 
  drop_na() %>% 
  ggplot() +
  ggtitle("h4pe23 vs h5pe3") +
  geom_jitter(aes(x = h5pe1, y = h4pe7, group = aid), alpha = .3, color = "light blue") +
  theme_dark()

# h4pe15 and h5pe2
h5pe2_change_plot <- final_data %>% 
  select(aid, h4pe7, h4pe15, h4pe23, h5pe1, h5pe2, h5pe3) %>% 
  drop_na() %>% 
  ggplot() +
  ggtitle("h4pe15 vs h5pe2") +
  geom_jitter(aes(x = h5pe2, y = h4pe15, group = aid), alpha = .3, color = "light blue") +
  theme_dark()

# h4pe23 and h5pe3
h5pe3_change_plot <- final_data %>% 
  select(aid, h4pe7, h4pe15, h4pe23, h5pe1, h5pe2, h5pe3) %>% 
  drop_na() %>% 
  ggplot() +
  ggtitle("h4pe23 vs h5pe3") +
  geom_jitter(aes(x = h5pe3, y = h4pe23, group = aid), alpha = .3, color = "light blue") +
  theme_dark()

gridExtra::grid.arrange(h5pe1_change_plot, h5pe2_change_plot, h5pe3_change_plot)
```

This plot explores the change across the waves 4 and 5 for the same question. The wave 4 outcome is on the y-axis and the wave 5 outcome is on the x-axis. We see that moving from wave 4 to wave 5 there was a scale change. Looking vertically (starting on the X axis and going vertically on the Y), we see that few values change in the extreme. Additionally, regardless of the value of `h5pe1` and `h5pe3`, the values from wave 4 primarily remain below 4. For `h5pe2`, the the data primarily remain at 5 or below.

# Look at predictor variables briefly
```{r histograms of predictors and outcomes}

# Replace missing values with 10 so they show on the plots
final_data %>% 
  mutate_all(~replace_na(., 10)) %>% 
  select(-c(h4pe7, h4pe15, h4pe23, h5pe1, h5pe2, h5pe3)) %>% 
  plot_histogram(title = "predictors")

# histograms of outcome variables
final_data %>% 
  select(h4pe7, h4pe15, h4pe23, h5pe1, h5pe2, h5pe3) %>% 
  mutate_all(~replace_na(.,10)) %>% 
  plot_histogram(title = "outcomes")
```

Note that in the above visualization, all missing values were replaced with the value 10. Additionally, the scale should be discrete. 

All predictors have variability - no predictor has only a single observed value. Interesting to note is the amount of missingness going from  `h4id5j`, `h5id6i`, both of which ask about being diagnosed with anxiety. Perhaps some of the missing information in `h5id6i` is captured in `h4id5j` and values could reasonably be imputed if needed. 

Additionally, the distributions going from the wave 4 to wave 5 predictors that are the same (see above under brief background and purpose) appear similar, though many values are missing in the wave 5 predictors.

# Look at correlation of predictor variables with outcome of interest
```{r correlation funnel for variables most of interest, warning=FALSE, cache=TRUE}
# Plot correlation funnel h4pe7 variable. Note, all missing values are dropped.
final_data %>% 
  select(-aid) %>% 
  drop_na() %>%
  correlationfunnel::correlate("h4pe7", method = "kendall") %>% 
  correlationfunnel::plot_correlation_funnel()
```

The correlation funnel above shows us that the most correlated variables with `h4pe7` are `h4pe23` and `h5pe1`, which make sense because they're both questions regarding optimism about the future. At the other end of the spectrum, we see that the least correlated variable is `h4mh18`, "How often was the following true during the past seven days? You were bothered by things that usually don't bother you." The penultimate variable, `h4id5j` appears to have almost identical correlated with `h4mh27` ("How often was the following true during the past seven days? You felt that people disliked you.") and `h4mh23` ("How often was the following true during the past seven days? You felt that you were too tired to do things."), which makes intuitive sense because these questions are dealing with unease and discomfort in the past week. 

Additional questions to ask and explore as needed when iterating:

  1. What does the correlation funnel tell us for the other optimism variables? \
  2. Are there observations that cluster together? (k-means, heirarchical, pca). \
  3. How does the outcome change across different clusters / groups? What's the variability? \
  4. How does heirarchical clustering compare to k-means clustering compare to PCA? \ 
  
  <br><br><br><br><br><br>