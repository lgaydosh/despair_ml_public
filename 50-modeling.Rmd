---
title: "50-modeling"
output: html_document
---

The purpose of this document is to create the final models used for the exploration in the file 60 series.

```{r load libraries}
library(pacman)
pacman::p_load(tidyverse, testit, furrr)
```

The following function is used to split the data
```{r split data function}
# df: dataframe to split
# strat_var: outcome variable to split on.  Can be a string if desired, e.g., outcome='h5mn8' ...%>%split_data(outcome)
# ratios: a list of the ratios for 2 or 3 splits.  Each split requires a ratio (e.g., train+test requires two ratios)
# returns: a list of dfs entitled 'train, test', or 'train, valid, test' corresponding to the input ratios.
split_data <- function(df, strat_var, ratios=c(0.7,0.2,0.1)){
  
  #assertions
  testit::assert("sum of the ratios must be 1!" , sum(ratios)==1.0)

  #split data
  splits <- df %>%
      rsample::initial_split(strat = {{strat_var}}, prop = sum(ratios[-length(ratios)]))
  
  #get data splits
  train = rsample::training(splits)
  test = rsample::testing(splits)
  
  #create split list for 2 splits
  split_list <- list(train = train,
                  test = test)
  
  #split for 3 splits
  if(length(ratios)==3){
    
    # Get data sizes
    data_szs <- nrow(df) * ratios
    
    # Get train/valid ratio
    new_ratio <- data_szs[[1]]/(data_szs[[1]] + data_szs[[2]])
    
    # Get new splits
    res <- split_data(train, strat_var, ratios=c(new_ratio, 1-new_ratio))
    split_list <- list(train=res$train,
                    valid=res$test,
                    test = test)
  }
  else if (length(ratios)!=2){
    stop('You can only have 2 or 3 splits in the data.')
  }
  
  return(split_list)
}

```

```{r ranking and visualization}
# Unused for now
# Get total value based on placement of variable importance
get_total_placement <- function(list){
  # list: a list of data frames returned from the get_top_n_names function
  # returns: a data frame grouped by all variables with sum total of placement
  
  out <- list %>%
    purrr::reduce(rbind) %>% 
    group_by(variable) %>% 
    summarise(total = sum(placement))
  
  # return tibble
  return(out)
}
```


```{r median placement of bootstrap performances}
get_median_placement <- function(input_list, use_base_var = FALSE){
  # list: a list of data frames returned from the get_top_n_names function
  # use_base_var: a boolean indicating if you want to reduce a one-hot encoded name to its base name
  # returns: a data frame grouped by all variables with median of the placements of those variables
  
  if(use_base_var == TRUE){
    
    out <- input_list %>%
    purrr::reduce(rbind) %>%
    dplyr::rename(oh_var = variable)%>%
    mutate(variable = str_split(oh_var,'[.]', simplify=TRUE)[,1]) %>%
    group_by(variable) %>% 
    dplyr::rename(predictor=variable) %>%
    summarise(median_rank = median(placement)) %>%
    arrange(median_rank) %>%
    mutate(overall_rank = 1:nrow(.))
    
  } else {
  out <- input_list %>%
    purrr::reduce(rbind) %>% 
    dplyr::rename(predictor=variable) %>%
    group_by(variable) %>% 
    summarise(median_rank = median(placement)) %>% 
    arrange(median_rank) %>%
    mutate(overall_rank = 1:nrow(.))
  }
  
  # return tibble
  return(out)
}
```

Both LASSO and RF can produce one-hot encoded variables/factors.  However, when we get the outputs, we need to be able to look up the variable and get the actual label that goes with it (e.g., 'FELT SAD').  This function puts those two things together - takes a variable like `h1fs1.3` , splits it into `h1fs1` and `3`, and then looks up the `h1fs1` in the ref_data.

```{r get attribute names}
#The purpose of this function is to get the attribute names from the one-hot encoded variable.  This is meant to be used with 
#a map_df function.
# var_str: input variable; can be a string, with or without the one-hot encoding
# ref_data: data which contains the labels for the variables. This could be full_dataset (dataset after joining waves)
# returns: a tibble with the lookup label
get_attribute_name <- function(var_str, ref_data){
  
  # split string
  res <- str_split(var_str, '[.]', simplify=TRUE)
  
  # Try to look up the variable
  lookup_name <- ref_data[[res[1,1]]]
  
  # If the lookup failed, return the original variable name.  Otherwise, return the label.
  if(is.null(lookup_name))
    att_name <- var_str
  else {
    # If no splitting was necessary (i.e. no one-hot encoding)
    if(length(res)==1) {
      att_name <- str_c(attributes(lookup_name))
    }
    else
      att_name <- str_c(attributes(lookup_name), '.', res[1,2])
  }
  
  # Return the name of interest.
  return(tibble(att_name))
}
```

```{r}
add_attribute_names <- function(att_df, col_name, ref_df){
  
  #browser()
  named_df <- map_df(att_df[[col_name]], get_attribute_name, ref_df) %>%
    bind_cols(att_df)
  
  return(named_df)
}
```


```{r}
# function to plot a boxplot showing the variance in feature placements
plot_median_placements <- function(df_placements, top_n = 20){
  # input: df_placements - dataframe with all variables in model and their median placements from the models
  # ouput: barplot of the median placements
  
  df_placements <- df_placements %>%   
    mutate(top_x = if_else(median_placement <= top_n, paste0("Top ", top_n), paste0("Not Top ", top_n)))
  
  df_placements %>% 
    drop_na() %>% 
    arrange(desc(median_placement)) %>%
    ggplot(aes(x = reorder(variable, -median_placement), y = median_placement)) +
    geom_col(aes(fill = top_x)) +
    geom_hline(yintercept = top_n, color = "yellow") +
    xlab("Predictor Variable") + 
    ylab("Median Placement") +
    ggtitle("Median Variable Importance based on Bootstrap") +
    coord_flip() +
    theme_dark()
  
}
```

```{r placement plots}
# function to plot a boxplot showing the variance in feature placements
plot_placement_boxplot <- function(placements){
  # input: list of placements from the bootstrapped samples
  # ouput: boxplot of placements of variables from the bootstraps
  
  
  combined_placements <- placements %>%
    purrr::reduce(rbind) %>% 
    drop_na()
  
  # Needs to be fixed so that axes don't overlap each other and obscure understanding
  combined_placements %>%
    group_by(variable)%>%
    ggplot() +
    geom_boxplot(aes(x = fct_reorder(variable, -placement), y = placement))+
    scale_x_discrete(expand = c(-0.001,0))+ 
    labs(y = "Placements", x = "Variables")+
    coord_flip()
  
}
```

```{r permute columns function}
######################
# Permute a single column of the data frame
permute_column <- function(df, column){
  # df: input data frame
  # column: column to permute
  
  df[,column] <- df %>% pull(column) %>% sample()
  return(df)
}

# Permute all columns (not outcome)
permute_columns <- function(df, outcome){
  # df: input data frame
  # outcome: outcome variable (not permuted)
  
  predictor_names <- df %>% dplyr::select(-outcome, -aid) %>% names()
  
  df_permute_list <- predictor_names %>% map(permute_column, df = df)
  
  names(df_permute_list) <- predictor_names
  
  return(df_permute_list)
}
```

```{r plot permutation importance}
######################
# plot the variable importance
plot_permute_var_imp <- function(df_permute_var_imp, metric){
  # df_permute_var_imp: data frame of permutation metrics from permute_var_imp()
  # metric: metric to plot, passed as a string
  # return: ggplot bar graph of permutation importance
  
  # create dataframe we can use for ggplot (mostly to grab the names below)
  plot_df <- df_permute_var_imp %>% 
    dplyr::select(predictor, metric, att_name)
  
  # Plot the metric
  plot_df %>% 
    ggplot() + 
    ylab(str_c(names(plot_df)[2], " ", "(True - Permuted)")) +
    xlab("Predictor") +
    ggtitle("Permutation Importance") +
    geom_bar(aes(x = reorder(att_name, !!sym(metric)), 
                 y = !!sym(metric)), 
             stat = "identity",
             fill = "light blue") +
    coord_flip() +
    theme_dark()
}

```


```{r permutation variable importance function}
# Note, make sure that factors are factors!
permute_var_imp <- function(df_predict, outcome, model_h2o, h2o_port_no){
  # df_predict: data to predict
  # outcome: outcome of interest
  # model_h2o: h2o model object
  # return: data frame of permutation importances
  
  # h2o.connect(port=h2o_port_no)
  
  # make permuted data frames h2o objects
  permute_list_h2o <- permute_columns(df = df_predict, outcome = outcome)
  
  # make prediction frame h2o object
  # df_predict_h2o <- df_predict %>% as.h2o()
  
  # Get metrics from unpermuted data
  true_metric_vals <- get_performance(test_data = df_predict, test_model = model_h2o, outcome = outcome)
  
  # get metrics for permuted data sets
  permuted_models_metric <- permute_list_h2o %>% 
    map(~get_performance(test_data = .x, test_model = model_h2o, outcome = outcome))
  
  # calculate permutation importance (dif. between permuted and non-permuted predictions)
  out <- permuted_models_metric %>%
    map_df(function(permute_mets = .x, real_mets = true_metric_vals) real_mets - permute_mets) %>% 
    mutate(variable = names(permute_list_h2o)) %>% 
    dplyr::select(variable, everything())
  
  return(out)
}

# example dataset
# mtcars2 <- mtcars %>% mutate(vs = factor(vs))

# example 1
# rf_h2o <- h2o.randomForest(x = c("mpg", "cyl", "disp"),
#                            y = "vs",
#                            training_frame = as.h2o(mtcars2))

# x <- permute_var_imp(df_predict = mtcars2, outcome = "vs", model_h2o = rf_h2o)

# example 2
# glm_h2o <- h2o.glm(x = c("mpg", "cyl", "disp"),
#                    y = "vs", 
#                    training_frame = as.h2o(mtcars2), 
#                    family = "binomial")

# x2 <- permute_var_imp(df_predict = mtcars2, outcome = "vs", model_h2o = glm_h2o)
# graph it
# plot_permute_var_imp(x, pr_auc)
# plot_permute_var_imp(x2, roc_auc)

# Example 3
# Use for how it will likely be implemented in the 70 series
# model_list <- list(glm_mod = glm_h2o, rf_mod = rf_h2o)
# y <- model_list %>%
#   map(~permute_var_imp(df_predict = mtcars2, outcome = "vs", model_h2o = .x))
# y$glm_mod %>% plot_permute_var_imp(pr_auc)
# y$rf_mod %>% plot_permute_var_imp(roc_auc)
```

```{r get permutation for all models}
# This function is a wrapper of permute_var_imp to work on a list of models
get_aggregated_permute_imp <- function(mdl_list, newdata_df, outcome, h2o_port){
  #mdl_list: list of models, e.g., generated from model_selection_bootstrap
  #newdata_df: the dataframe you wish to compute the permutation importance upon
  #outcome: outcome of interest
  #returns: tibble of aggregated results
  agg_pi <- mdl_list %>%
    future_map_dfr(~permute_var_imp(df_predict=newdata_df, outcome=outcome, model_h2o=.x, h2o_port_no=h2o_port)) %>%
    as_tibble()
  
  return(agg_pi)
}
```

```{r get aggregated permutation importance for all models}
# This function returns the overall placements of the features using the aggregated list of permutated feature importances
get_permute_placement <- function(agg_permute_df, metric_oi='pr_auc'){
  #agg_permute_df: aggregated metrics of permuted variables (e.g., from get_aggregated_permute_imp)
  #metric_oi: the metric of interest to be pulled from the dataframe
  #returns: returns overall ordered placements for each of the predictors
  
  var_placements <- agg_permute_df %>%
    group_by(variable) %>%
    summarise_all(mean) %>%
    dplyr::arrange(desc(get(metric_oi))) %>%
    mutate(overall_rank = 1:nrow(.)) %>%
    dplyr::rename(predictor=variable) %>%
    dplyr::select(predictor, overall_rank, all_of(metric_oi))
  
  return(var_placements)
}
```

