---
title: "41-modeling-RF"
output: html_notebook
---

```{r}
library(data.table)
library(mlr)
library(splitstackshape)
library(boot)
library(tidyverse)
library(rsample)
```

**Steps Taken**

1. Splitting the data. [x]
2. Bootstrapping the training set n times (n = 1000). [x]
3. Splitting the bootstrap set into a training a validation set. [x]
4. Creating n different models. [x]
- finding the best tuning parameters for each model using grid search (Tuning parameters: ntrees and max_depth).[x]
- creating a final model (using k-fold cross validation) that uses the best tuning parameters from the previously conducted grid search.[x]
- fitting the model onto the validation set created earlier.[x]
5. Saving all models and the performance metrics into a list. [x]
6. Evaluation of all model parameters and the stability of those parameters.  


```{r}
## these three variables could get out from the rf_suicide.
  straps_splits <- stratified(as.data.frame(train), c("h5mn8"), 0.9, bothSets = T) 
  
  training_frame <- straps_splits[[1]]
  validation_frame <- straps_splits[[2]]
```






```{r random forest model function}
# The steps are not in order because the function needed to be created first.
rf_suicide <- function(training_frame,         
                       validation_frameï¼Œ
                      #train,           # training set or bootstrap
                       k = 5,               # ks of k fold
                       max_depths_tune, # vector of max_depths to test on
                       ntree_tune){     # vector of ntrees to test on
  
  model_list <- vector(mode = "list", length = n) # creating an empty list to save all the models
  results_list <- vector(mode = "list", length = n) # creating an empty list to save all the model validation results
  
  
  #straps$splits[[i]]
  # Step 3
  # straps_splits <- stratified(as.data.frame(train), c("h5mn8"), 0.9, bothSets = T) 
  # 
  # training_frame <- straps_splits[[1]]
  # validation_frame <- straps_splits[[2]]
  
  # Step 4
  params <- expand.grid(max_depth = seq(7,8), ntrees = seq(200,201))
  
  model_tune_list <- rep(NA, nrow(params))
  
  for(i in 1:nrow(params)){
    rf_i <- h2o.randomForest(
      training_frame = as.h2o(training_frame),
      x=setdiff(data_subset_list, c("h5mn8")),
      y="h5mn8", 
      model_id = "rf_covType_v1",
      max_depth = params[i,][[1]],
      ntrees = params[i,][[2]], 
      stopping_rounds = 2,
      nfolds = 5,
      fold_assignment = "Stratified",
      score_each_iteration = T,
      seed = 42
    )
    
    result <- h2o.performance(rf_i, as.h2o(validation_frame))
    
    model_tune_list[i] <- result@metrics$AUC
  }
  
  best_index <- which(model_tune_list==max(model_tune_list))[1]
  
  rf_i <- h2o.randomForest(
    training_frame = as.h2o(training_frame),
    x=setdiff(data_subset_list, c("h5mn8")),
    y="h5mn8", 
    model_id = "rf_covType_v1",
    ntrees = params[best_index,2], 
    max_depth = params[best_index,1],
    stopping_rounds = 2,
    nfolds = k,
    fold_assignment = "Stratified",
    score_each_iteration = T,
    seed = 42
  )
  
  # model_list[i] <- rf_i
  # results_list[i] <- h2o.performance(rf_i, as.h2o(validation_frame))
  
  return(list(rf_i, h2o.performance(rf_i, as.h2o(validation_frame))))
}

```


# Creating the subset of the dataset we will be using for the model
Note:
1. Have not added age, race and sex/gender information in this subset as of yet. 
2. Initially creating the model to predict suicidal ideation at wave 5. 
3. Initially making the decision to remove all NA values in wave 5.

```{r}

# Step 1
data_subset_list <- setdiff(predictor_list, "aid") %>% append("h5mn8") # list of variables to use 
data_subsets <- joined_waves[data_subset_list] %>% na.omit() # subsetting the data based on the variables
splits <- stratified(data_subsets, c("h5mn8"), 0.7, bothSets = T) 
train <- splits[[1]]
test <- splits[[2]]


# Step 2
n =2 # input 
straps <- train %>% bootstraps(times = n, strata = "h5mn8")

combined_models <- vector(mode = "list", length = n)
combined_performances <- vector(mode = "list", length = n)


# These are the tuning parameters that we decide to tune.
max_depths <- c(5,10,25)
ntrees <- c(100,150,200)


for(i in 1:length(straps)){
  results <- as.data.frame(straps$splits[[i]])%>%
    rf_suicide()
  
  print(results)
  
  combined_models[i] <- results[1]
  combined_performances[i] <- results[2]

}

#results[1]
combined_models[1]
combined_performances[1]

# results[2]
# 
# 
# str(results)
```

```{r}
resul
```


```{r}
results[[2]]
```








