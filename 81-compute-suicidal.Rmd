---
title: "81-compute-suicidal"
output: html_document
---

#81-compute-suicidal

This notebook is used with SLURM for the purpose of computing all data regarding suicidal ideation; this includes bootstrap model performance on validation sets, permutation importance tables, and MDI tables among others.  See `81-interpret-suicidal` for more information on data selection, predictors, and outcome variables.

## Usage
To use this file, you'll need to actually run it from slurm_experiments.R.  This will drop in some of the variables which are not present here, including `n_boot`, `seed`, `task_ID`, and `results_directory`.

```{r load libraries, include=FALSE}
# Use pacman, which forces an install if the library isn't present on the running machine
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, h2o, furrr, tictoc)
```

```{r source files}
rsource_dir = 'r_project_source'
source_files_list <- list.files(rsource_dir)
map(str_c(rsource_dir, '/', source_files_list), source)
```

```{r initializations, include=FALSE}
port_no <- start_h2o()
h2o.no_progress()
future::plan(multiprocess)
```

```{r seeds for reproducibility}
# define seed (defined in slurm_experiments.R)
seed = 9384
h2o_seed = -1
set.seed(seed)
```

# Dataset generation

The predictors we will be using will be several variable lists loaded from `10-import-data.Rmd` file. These initial set of predictors will be based of the list of variables that describe anxiety, depression, optimism, some demographics, and biological despair.

```{r load raw data and formulate dataset, warning=TRUE, message=TRUE}
## set outcome variable of interest
filebase = '/scratch/p_gaydosh_dsi'

#create data in specified form
write(str_c("\n\nGenerating the data...\n\n"), log_file, append=TRUE)
dataset_list <- generate_datasets(outcome, binarize=FALSE, filebase=filebase, seed_val=seed)
write(str_c('Dataset generation parameters - Seed: ', seed), log_file, append=TRUE)

#parse out dataset components
full_dataset <- dataset_list$full_dataset
ds_raw <- dataset_list$ds_raw_outcome
ds <- dataset_list$ds_final

#ml splits of the data
write(str_c("\n\nSplitting the data...\n\n"), log_file, append=TRUE)
training_df <- dataset_list$training_df
validation_df <- dataset_list$validation_df
testing_df <- dataset_list$testing_df

```


# Robust feature evaluation {.tabset .tabset-fade .tabset-pills}

## RF model

```{r feature selection rf, include=FALSE}

write("\n\nBootstrapping RF models...", log_file, append=TRUE)

tic()
# Spans of hyper parameters for random forest
rf_params <- list(max_depth = 50,
                  ntrees = 150,
                  mtries = c(-1, 20, by=5),
                  min_rows = c(2, 15, by=2),
                  #stopping_rounds = 3,
                  #balance_classes = c(TRUE, FALSE),
                  #stopping_metric = 'AUCPR',
                  categorical_encoding = 'one_hot_explicit')

# define number of bootstraps (defined in slurm_experiments.R)
#n_boot = 2

boots_rf <- model_feature_selection("RF",training_frame = training_df,
                      validation_frame = validation_df,
                      hyper_params = rf_params,
                      outcome = outcome, n = n_boot, seed=seed, h2o_seed = h2o_seed)

toc()

write("RF bootstrapping completed\n\n", log_file, append=TRUE)
```

```{r get rf bootstrap model seeds and save}

write("\n\nSaving RF bootstrap model seeds...", log_file, append=TRUE)

bs_rf_seeds <- get_model_seeds(boots_rf$models)

save_to_csv(bs_rf_seeds, results_directory, task_ID)

write("RF bootstrap seeds saved\n\n", log_file, append=TRUE)

```


```{r save/load rf bootstrap model performance, include=FALSE}

write("\n\nAggregating random forest performance results...", log_file, append=TRUE)

bs_rf_perf <- get_metric_set_from_perfs(boots_rf$perfs) %>%
  dplyr::select(accuracy, mpce, sens, spec, ppv, npv, roc_auc, pr_auc,
                tns, tps, fns, fps, no_n, no_p,  err_rate, bal_accuracy, everything())

save_to_csv(bs_rf_perf, results_directory, task_ID)

write("RF bootstrap metrics calculated\n\n", log_file, append=TRUE)
```

### Feature importances: Random Forest
#### Mean decrease in impurity (MDI)

```{r save/load rf bootstrap model mdi, include=FALSE}
write("\n\nCalculating RF bootstrap MDI...", log_file, append=TRUE)

bs_rf_mdi <- boots_rf$mdi %>% 
  purrr::reduce(rbind)

save_to_csv(bs_rf_mdi, results_directory, task_ID)

write("RF bootstrap MDI calculated\n\n", log_file, append=TRUE)

```


#### Permutation importance
Calculate and save permutation importance

```{r compute/save or load bs rf model permutation, include=FALSE}
write("\n\nCalculating RF bootstrap permutation importance...", log_file, append=TRUE)

tic()
bs_rf_perm_plt <- boots_rf$models %>%
  get_aggregated_permute_imp(training_df, outcome=outcome, h2o_port=port_no)

toc()

save_to_csv(bs_rf_perm_plt, results_directory, task_ID)

write("Bootstrap RF permutation importance completed\n\n", log_file, append=TRUE)

```

```{r clear memory after rf perm imp}
h2o.removeAll()
```


## LASSO model
In this step, we model the relation between the outcomes and the predictors using a linear regression with L2 regularization.  This drives the importance of unimportant and redudant features towards zero.

```{r feature selection lasso, message=FALSE, warning=FALSE}
write("\n\nGenerating bootstrap models for LASSO...", log_file, append=TRUE)
# Function parameters
lasso_params <- list(alpha = c(1))

boots_lasso <- model_feature_selection( "Lasso",
                                          training_frame = training_df,
                                          validation_frame = validation_df,
                                          hyper_params = lasso_params,
                                          outcome = outcome, 
                                          n = n_boot,
                                          seed=seed,
                                          h2o_seed=h2o_seed)

write("Bootstrap models for LASSO completed\n\n", log_file, append=TRUE)
```

```{r get lasso bootstrap model seeds and save}
write("\n\nSaving LASSO bootstrap seeds...", log_file, append=TRUE)

bs_lasso_seeds <- get_model_seeds(boots_lasso$models)

save_to_csv(bs_lasso_seeds, results_directory, task_ID)

write("Seeds for LASSO saved\n\n", log_file, append=TRUE)
```

```{r save/load lasso bootstrap model performance, include=FALSE}

write("\n\nCalculating and saving LASSO bootstrap model performance...", log_file, append=TRUE)

bs_lasso_perf <- get_metric_set_from_perfs(boots_lasso$perfs) %>%
  dplyr::select(accuracy, mpce, sens, spec, ppv, npv, roc_auc, pr_auc,
                tns, tps, fns, fps, no_n, no_p,  err_rate, bal_accuracy, everything())

save_to_csv(bs_lasso_perf, results_directory, task_ID)

write("LASSO bootstrap model and performance saved\n\n", log_file, append=TRUE)

```

### Feature importances: LASSO
#### Coefficient-based variable importance

```{r save/load lasso bootstrap model mdi, include=FALSE}

write("\n\nCalcuating LASSO coefficient-based variable importance...", log_file, append=TRUE)

bs_lasso_mdi <- boots_lasso$mdi %>% 
  purrr::reduce(rbind)

save_to_csv(bs_lasso_mdi, results_directory, task_ID)

write("Coefficient-based variable importance calculated\n\n", log_file, append=TRUE)
```

#### Permutation importance

```{r compute/save or load bs lasso model permutation, include=FALSE}

write("\n\nCalcuating LASSO permutation importance...", log_file, append=TRUE)

bs_lasso_perm_plt <- boots_lasso$models %>%
  get_aggregated_permute_imp(training_df, outcome=outcome, h2o_port=port_no)

save_to_csv(bs_lasso_perm_plt, results_directory, task_ID)
  
write("Permutation importance calculated...\n\n", log_file, append=TRUE)
```

```{r clear memory after lasso perm imp}
h2o.removeAll()
```

# Generation of final model {.tabset .tabset-fade .tabset-pills}

## Add folds to training set
```{r join with kfold assignments}
write("\n\nAdding kfold assignments to the training data...", log_file, append=TRUE)

if(!is.null(kfold_file)){
  
  #read kfold assignments
  kfold_assigns = read_csv(kfold_file, col_types = cols(aid=col_character(), fold_assign=col_factor()))
  
  #join with training_df
  start_len = nrow(training_df)
  training_df <- full_join(training_df, kfold_assigns, by='aid')
  
  #make sure that all of these things have the same length
  if((nrow(training_df)!= start_len) | nrow(training_df) != nrow(kfold_assigns)){
    stop('training df, kfold_assigns, and the joined df do not appear to have the same number of rows!')
  }
}

write("Training set folds added\n\n", log_file, append=TRUE)
```

## RF model
In this step, we build the final model for the random forest.  We use slightly more values in order to come up with the best model, keeping in mind the number of combinations that are required to run to evaluate the grid.
```{r final model evaluation rf}

write("\n\nTraining final random forest...", log_file, append=TRUE)

# # Spans of hyper parameters for random forest
rf_params <- list(max_depth = 50,
                  ntrees = 150,
                  mtries = seq(-1, 20, by=5),
                  min_rows = seq(2, 20, by=2),
                  #stopping_rounds = 3,
                  #balance_classes = c(TRUE, FALSE),
                  #stopping_metric = 'AUCPR',
                  categorical_encoding = 'one_hot_explicit')

# Function parameters
final_model_rf <- rf_model(outcome,
                           training_frame = training_df,
                           validation_frame = validation_df,
                           #nfolds = 5,
                           fold_column = 'fold_assign',
                           hyper_params = rf_params, model_seed=h2o_seed)

write("Final random forest trained.\n\n", log_file, append=TRUE)

```

```{r get rf final model seeds and save}
write("\n\nSaving final random forest seeds...", log_file, append=TRUE)

final_rf_seeds <- get_model_seeds(list(final_model_rf[[1]]))

save_to_csv(final_rf_seeds, results_directory, task_ID)

write("Random forest final seeds saved.\n\n", log_file, append=TRUE)
```

```{r save/load final rf model}
write("\n\nSaving random forest final model and performance", log_file, append=TRUE)

#get performance and model
final_rf_perf <-final_model_rf[[2]]
final_rf_model <- final_model_rf[[1]]

#save performance to file
save_to_csv(final_rf_perf, results_directory, task_ID)

#save model to file
save_h2o_model(final_rf_model, results_directory, task_ID)

write("Final RF model saving completed\n\n", log_file, append=TRUE)
```

### Features: permutation importance

```{r compute/save or load final rf model permutation}
write("\n\nCalculating final RF permutation importance...", log_file, append=TRUE)

final_rf_perm_plt <- list(final_model_rf[[1]]) %>%
  get_aggregated_permute_imp(dplyr::select(training_df, -fold_assign),
                             outcome=outcome, h2o_port=port_no)

save_to_csv(final_rf_perm_plt, results_directory, task_ID)

write("Final RF permutation importance completed\n\n", log_file, append=TRUE)
```

```{r clear memory between final model perm imp}
h2o.removeAll()
```

## LASSO model
Now, we create the final model for LASSO.  There is no substantial difference between this method and the bootstrap methods, other than the data upon which the model is being built.
```{r final model evaluation lasso, message=FALSE, warning=FALSE}

write("\n\nTraining final LASSO...", log_file, append=TRUE)
# Function parameters
lasso_params <- list(alpha = c(1))

final_model_lasso <- lasso_model(training_frame = training_df,
                                 validation_frame = validation_df,
                                 outcome = outcome,
                                 #nfolds = 5,
                                 fold_column = 'fold_assign',
                                 hyper_params = lasso_params,
                                 model_seed = h2o_seed)

write("Final LASSO trained\n\n", log_file, append=TRUE)
```

```{r get lasso final model seeds and save}
write("\n\nSaving final LASSO seeds...", log_file, append=TRUE)

final_lasso_seeds <- get_model_seeds(list(final_model_lasso[[1]]))

save_to_csv(final_lasso_seeds, results_directory, task_ID)

write("Final LASSO seeds saved\n\n", log_file, append=TRUE)
```

```{r save/load final lasso model}
write("\n\nSaving LASSO performance and models...", log_file, append=TRUE)
  
#get performance and model
final_lasso_perf <-final_model_lasso[[2]]
final_lasso_model <- final_model_lasso[[1]]

#save performance
save_to_csv(final_lasso_perf, results_directory, task_ID)

#save model
save_h2o_model(final_lasso_model, results_directory, task_ID)

write("Final LASSO model and performance saved\n\n", log_file, append=TRUE)
```

### Features: permutation importance

```{r compute/save or load final lasso model permutation}
write("\n\nCalculating final LASSO permutation importance", log_file, append=TRUE)

final_lasso_perm_plt <- list(final_model_lasso[[1]]) %>%
  get_aggregated_permute_imp(dplyr::select(training_df, -fold_assign),
                             outcome=outcome, h2o_port=port_no)

save_to_csv(final_lasso_perm_plt, results_directory, task_ID)

write("LASSO permutation importance completed\n\n", log_file, append=TRUE)
```

# Other cleanup
```{r shutdown h2o instance}
h2o.shutdown(FALSE)
```
