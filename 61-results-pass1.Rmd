---
title: "61-results-pass1"
output: html_document
---

The purpose of this document is to explore the results of the models built in the 50 series.

```{r load libraries}
# These are libraries needed to run the code below
```

```{r convenience functions}

# This function returns the metric from an h20 model fit
get_metrics <- function(df, h2o_model){
  # df: training or testing frame
  # h2o_model: h2o model fit to use
  # returns: tibble of metrics
  
  h2o_df <- df %>% as.h2o()
  
  # calculate result
  result <- h2o.performance(model = h2o_model, newdata = h2o_df)
  
  # get metrics of interest
  metrics <- tibble(auc = result@metrics$AUC, 
                    mse = result@metrics$MSE, 
                    rmse = result@metrics$RMSE,
                    r2 = result@metrics$r2,
                    logloss = result@metrics$logloss)
  
  # return metric tibble
  return(metrics)
  
}


# Get total value based on placement of variable importance
get_total_placement <- function(df){
  # df: a data frame returned from the get_top_n_names function
  # returns: a data frame grouped by all variables with sum total of placement
  
  out <- df %>%
    bind_rows() %>% 
    group_by(variable) %>% 
    summarise(total = sum(placement))
  
  # return tibble
  return(out)
}
```

```{r explore variable importance for suicide}
# This will give you a data frame of top predictors

top_preds_outcome <- variable_imps %>%
  get_total_placement() %>% 
  mutate(avg_place = total /2,
         top_20 = if_else(avg_place <= 20, "Top 20", "Not Top 20"))

# Plot top predictors
top_preds_outcome %>% 
  arrange(desc(total)) %>%
  ggplot(aes(x = reorder(variable, -avg_place), y = avg_place)) +
  geom_col(aes(fill = top_20)) +
  geom_hline(yintercept = 20, color = "yellow") +
  xlab("Predictor Variable") + 
  ylab("Average Importance") +
  ggtitle("Variable Importance based on Bootstrap") +
  coord_flip() +
  theme_dark()

```

```{r final random forest model for suicide ideation}
outcome <- c("h5mn8")

# final features are the top variables extracted from the previous chunk
final_features <- top_preds_outcome$variable
tuning_param <- expand.grid(max_depth = c(7,8,9,10), ntrees = c(100,150,200,250))
model_tune_list <- rep(NA, nrow(tuning_param))

for(i in 1:nrow(tuning_param)){
  rf_i <- h2o.randomForest(
    training_frame = as.h2o(training_df),
    x=final_features,
    y= outcome, 
    model_id = "rf_covType_v1",
    max_depth = tuning_param[i,][[1]],
    ntrees = tuning_param[i,][[2]], 
    stopping_rounds = 2,
    nfolds = 5,
    fold_assignment = "Stratified",
    score_each_iteration = T,
    seed = 42
  )
  
  result <- h2o.performance(rf_i, as.h2o(training_df))
  
  model_tune_list[i] <- result@metrics$AUC
}

best_index <- which(model_tune_list==max(model_tune_list))[1]


rf_final_model <- h2o.randomForest(
  training_frame = as.h2o(training_df),
  x=final_features,
  y=outcome, 
  model_id = "rf_covType_v1",
  ntrees = tuning_param[best_index,][[2]], 
  max_depth = tuning_param[best_index,][[1]],
  stopping_rounds = 2,
  nfolds = 5,
  fold_assignment = "Stratified",
  score_each_iteration = T,
  seed = 42
)
```

```{r explore results}
# get results for testing frame
results <- testing_df %>% 
  get_metrics(h2o_model = rf_final_model)
```