---
title: "71-experiments-lasso"
output:
  html_notebook:
    code_folding: hide
    theme: lumen
    toc: yes
    toc_float: yes
    toc_depth: 4
  html_document:
    df_print: paged
    toc: yes
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r source files}
source("function_import.R")
```

**Purpose.** In this work, we will explore the relation between identified measures of despair of interest (e.g., personality measures of self-consciousness, individual and composite item scores from the CES-D assessment) and descriptors of diseases of despair.  We will achieve this goal through modeling the outcomes based on the included predictors, and robustly assess the importance of the included features in predicting the outcomes via bootstrapping.  We will use two well-known machine learning models, random forests and LASSO, which are both frequently used to measure the relative importance of the predictors included in the models.  Lastly, we'll generate trained and tuned models using this reduced feature set which can be used by others wish to predict the identified outcomes.

**Subject inclusion.** For this investigation, we will omit the entirety of Wave 2.  This is commonly done in analyses of AddHealth data due the design of the original study.  Otherwise, our dataset will include only subjects who have predictor and outcome data in _all_ of the waves.

**Outcome variables.** In this experiment, we assess _suicidal ideation_ at Wave 5.  

**Predictor variables.** The predictors for these models are hand-picked, and based on previous work, relevance, and subject matter expertise. The set of predictors and the set of outcomes are disjoint.  Predictors from Waves 1-4 (excluding Wave 2, see above) are included, and will be detailed in the following analysis.

```{r load libraries, include=FALSE}
# Use pacman, which forces an install if the library isn't present on the running machine
if (!require("pacman")) install.packages("pacman")
#pacman::p_install(plotly)
pacman::p_load(tidyverse, h2o, furrr, tictoc)

```

```{r initializations, include=FALSE}
port_no <- start_h2o()
h2o.no_progress()
future::plan(multisession, workers=11)
```

```{r seeds for reproducibility}
seed= 9384
h2o_seed=-1
set.seed(seed)
```

# Dataset generation

The predictors we will be using will be the the variable `predictor_list` loaded from `10-import-data.Rmd` file. These initial set of predictors will be based of the list of variables that describe anxiety, depression, and optimism.

```{r load raw data and formulate dataset, warning=TRUE, message=TRUE}
## set outcome variable of interest
outcome = 'h5mn8'
filebase = '/scratch/p_gaydosh_dsi'
results_directory = str_c(filebase, '/DSI/', outcome, '/', Sys.Date(), '/lasso')
n_boot = 5

#create data in specified form
dataset_list <- generate_datasets(outcome, binarize=FALSE, filebase=filebase, seed_val=seed)

#parse out dataset components
wave_data <- dataset_list$wave_data
full_dataset <- dataset_list$full_dataset
ds_raw <- dataset_list$ds_raw_outcome
ds <- dataset_list$ds_final

#ml splits of the data
training_df <- dataset_list$training_df
validation_df <- dataset_list$validation_df
testing_df <- dataset_list$testing_df

```

## LASSO model
In this step, we model the relation between the outcomes and the predictors using a linear regression with L2 regularization.  This drives the importance of unimportant and redudant features towards zero.

```{r feature selection lasso}
# Function parameters
lasso_params <- list(alpha = c(1))
# Call modeling function using function parameters and show visualization of results.  Recommend the number of features that should be used.  Report performance metric stats.
tic()
boots_lasso <- model_feature_selection( "Lasso",
                                        training_frame = training_df,
                                        validation_frame = validation_df,
                                        hyper_params = lasso_params,
                                        outcome = outcome, 
                                        n = n_boot,
                                        seed=seed,
                                        h2o_seed=h2o_seed)
toc()
```

```{r get lasso seeds and performance}
bs_lasso_seeds <- get_model_seeds(boots_lasso$models)

bs_lasso_perf <- get_metric_set_from_perfs(boots_lasso$perfs) %>%
  dplyr::select(accuracy, mpce, sens, spec, ppv, npv, roc_auc, pr_auc,
                tns, tps, fns, fps, no_n, no_p,  err_rate, bal_accuracy, everything())
#bs_lasso_perf
```


```{r evaluate bootstrap model performance lasso, warning=FALSE, message=FALSE}
mean_bs_lasso_perf <- bs_lasso_perf %>%
  summarise_if(is.numeric, mean, na.rm=TRUE) %>% 
  mutate(model='bs_lasso') %>%
  dplyr::select(model, everything())

mean_bs_lasso_perf
```

### Feature importances: LASSO
#### Coefficient-based variable importance
```{r}
boot_lasso_mdi <- boots_lasso$mdi %>%
  get_median_placement(use_base_var = TRUE) %>%
  add_attribute_names('predictor', full_dataset) %>%
  dplyr::select(predictor, att_name, overall_rank)

head(boot_lasso_mdi, 20)
```

```{r fig.width = 10, fig.height = 12}
plot_placement_boxplot(boots_lasso$mdi)
```

#### Permutation importance
```{r message=FALSE, warning=FALSE}
tic()
boot_lasso_perm_plt <- boots_lasso$models %>%
  get_aggregated_permute_imp(training_df, outcome=outcome, h2o_port=port_no)
toc()
```

```{r aggregate lasso permutations and get metrics}
met <- 'pr_auc'
boot_lasso_perm <- boot_lasso_perm_plt %>%
  get_permute_placement(metric_oi=met) %>% #set in random forest section
  add_attribute_names('predictor', full_dataset) %>%
  dplyr::select(predictor, everything())

head(boot_lasso_perm, 20)
```

```{r plot lasso permutation, fig.width = 10, fig.height = 12}
plot_permute_var_imp(boot_lasso_perm, metric = met)
```

#### Coefficient vs. Permutation importance
Now, we compare the feature importances generated by the two different approaches.  The traditional method of evaluating feature importance for regression methods is through analysis of the coefficients.
```{r fig.width = 16, fig.height = 14}
cbind(boot_lasso_mdi[1:20,], dplyr::select(boot_lasso_perm[1:20,], -met))
```


# Save data and models
```{r}
#data
save_var_list <- c('bs_lasso_perf',
                   'mean_bs_lasso_perf',
                   'bs_lasso_seeds',
                   'boot_lasso_perm_plt',
                   'boot_lasso_mdi')

dir_create(results_directory)
save(list=save_var_list, file=str_c(results_directory, '/', 'experimental_lasso_results.RData'))

```

# Other cleanup
```{r shutdown h2o instance}
h2o.shutdown(FALSE)
```



